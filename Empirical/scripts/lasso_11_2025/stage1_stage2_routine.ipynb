{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from stage1 import lasso_rolling_window, calculate_r_squared\n",
    "from stage2 import estimate_kappa_curve_fit, compute_alm_returns, compute_stage2_r_squared\n",
    "from grid_search import estimate_single_config, grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b47ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(os.getenv(\"LASSO_OUTPUT_DIR\", \"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = Path(\"output\") / \"features.pkl\"\n",
    "response_path = Path(\"output\") / \"response.pkl\"\n",
    "return_path = Path(\"data\") / \"return84_20.csv\"\n",
    "\n",
    "with features_path.open(\"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "with response_path.open(\"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "if not return_path.exists():\n",
    "    return_path = Path(r\"C:\\Users\\jonat\\Lasso_paper\\Empirical\\data\\return84_20.csv\")\n",
    "    print(\"Using absolute path:\", return_path)\n",
    "\n",
    "y = np.log(y+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afddc7",
   "metadata": {},
   "source": [
    "\n",
    "### We now estimated the 1st stage under the assumption that the agents PLM is estimated by LASSO.\n",
    "\n",
    "The next step is now to use these forecasted returns to estimate the ALM.\n",
    "The ALM in the 2nd stage is specified as: \n",
    "\n",
    "$$\n",
    "r_{t+1} = \\log(\\varepsilon_{t+1}) \n",
    "+ \\log(1 - \\kappa e^{x'_t \\beta}) \n",
    "- \\log(1 - \\kappa e^{x'_{t+1} \\beta})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\kappa := \\delta a^{-\\gamma} \\phi\n",
    "$$\n",
    "\n",
    "Here, $x'_t \\beta$ and $x'_{t+1} \\beta$ are the $t$ and $t+1$ return foreacsts of the agent from the 1st stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc724c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Configuration ---\n",
    "# lambda_values = [0.01, 0.001]\n",
    "# WINDOW_SIZE = 30\n",
    "# N_LAGS = 3\n",
    "\n",
    "# def compute_alm_returns(predictions, kappa, intercept):\n",
    "#     \"\"\"Compute ALM-implied realized returns.\"\"\"\n",
    "#     pred_t, pred_t1 = predictions[:-1], predictions[1:]\n",
    "#     valid = (1 - kappa * np.exp(pred_t) > 0) & (1 - kappa * np.exp(pred_t1) > 0)\n",
    "    \n",
    "#     if not np.all(valid):\n",
    "#         valid_idx = np.where(valid)[0]\n",
    "#         pred_t, pred_t1 = pred_t[valid_idx], pred_t1[valid_idx]\n",
    "    \n",
    "#     return np.log(1 - kappa * np.exp(pred_t)) - np.log(1 - kappa * np.exp(pred_t1)) + intercept\n",
    "\n",
    "# def calculate_r_squared(y_true, y_pred):\n",
    "#     \"\"\"Calculate R-squared.\"\"\"\n",
    "#     ss_total = np.sum((y_true - np.mean(y_true))**2)\n",
    "#     ss_residual = np.sum((y_true - y_pred)**2)\n",
    "#     return 1 - (ss_residual / ss_total)\n",
    "\n",
    "# def process_lambda(lam, X, y):\n",
    "#     \"\"\"Process a single lambda value through both stages.\"\"\"\n",
    "#     print(f\"\\nProcessing λ = {lam:.6f}...\")\n",
    "    \n",
    "#     # Stage 1: Rolling LASSO\n",
    "#     lasso_results = lasso_rolling_window(\n",
    "#         X=X, y=y, window_size=WINDOW_SIZE, n_lags=N_LAGS,\n",
    "#         lambda_mode=\"fixed\", fixed_lambda=lam, verbose=False\n",
    "#     )\n",
    "    \n",
    "#     preds = np.array(lasso_results[\"predictions\"])\n",
    "#     y_valid = y[-len(preds):] if not isinstance(y, pd.Series) else y.iloc[-len(preds):]\n",
    "#     y_vals = y_valid.values if isinstance(y_valid, pd.Series) else y_valid\n",
    "    \n",
    "#     # Stage 1 metrics\n",
    "#     residuals = y_vals - preds\n",
    "#     r2_stage1 = calculate_r_squared(y_vals, preds)\n",
    "#     phi = np.exp(0.5 * np.var(residuals))\n",
    "#     insample_r2 = np.mean(lasso_results['insample_r_squareds'])\n",
    "    \n",
    "#     # Stage 2: Estimate kappa\n",
    "#     stage2_input = pd.DataFrame({\"vwretd\": y_vals, \"predictions\": preds})\n",
    "#     kappa, intercept, kappa_tstat, intercept_tstat, r2_stage2 = np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "#     try:\n",
    "#         popt, pcov = estimate_kappa_curve_fit(stage2_input)\n",
    "#         kappa, intercept = popt\n",
    "#         se = np.sqrt(np.diag(pcov))\n",
    "#         kappa_tstat, intercept_tstat = kappa / se[0], intercept / se[1]\n",
    "        \n",
    "#         # Stage 2 R-squared\n",
    "#         alm_rets = compute_alm_returns(preds, kappa, intercept)\n",
    "#         r2_stage2 = calculate_r_squared(y_vals[1:len(alm_rets)+1], alm_rets)\n",
    "        \n",
    "#         # Store ALM returns\n",
    "#         alm_df = pd.DataFrame({\n",
    "#             \"date\": y_valid.index[1:len(alm_rets)+1] if isinstance(y_valid, pd.Series) else range(len(alm_rets)),\n",
    "#             \"r_hat\": alm_rets,\n",
    "#             \"lambda\": lam\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ Kappa estimation failed: {e}\")\n",
    "#         alm_df = None\n",
    "    \n",
    "#     # Active predictors\n",
    "#     coefs = np.array(lasso_results[\"coefficients\"])\n",
    "#     active_counts = np.count_nonzero(coefs, axis=1)\n",
    "#     dates = pd.to_datetime(lasso_results.get(\"window_end_dates\", pd.RangeIndex(len(active_counts))))\n",
    "    \n",
    "#     active_df = pd.DataFrame({\n",
    "#         \"date\": dates,\n",
    "#         \"active_predictors\": active_counts,\n",
    "#         \"lambda\": lam\n",
    "#     })\n",
    "    \n",
    "#     return {\n",
    "#         \"summary\": {\n",
    "#             \"lambda\": lam,\n",
    "#             \"kappa\": kappa,\n",
    "#             \"kappa_tstat\": kappa_tstat,\n",
    "#             \"intercept\": intercept,\n",
    "#             \"intercept_tstat\": intercept_tstat,\n",
    "#             \"avg_active_predictors\": np.mean(active_counts),\n",
    "#             \"insample_r_squared\": insample_r2,\n",
    "#             \"r_squared_stage_1\": r2_stage1,\n",
    "#             \"phi_stage_1\": phi,\n",
    "#             \"r_squared_stage_2\": r2_stage2\n",
    "#         },\n",
    "#         \"active_df\": active_df,\n",
    "#         \"alm_df\": alm_df\n",
    "#     }\n",
    "\n",
    "# # --- Main Execution ---\n",
    "# results = [process_lambda(lam, X, y) for lam in lambda_values]\n",
    "\n",
    "# # Aggregate results\n",
    "# results_df = pd.DataFrame([r[\"summary\"] for r in results])\n",
    "# active_predictors_df = pd.concat([r[\"active_df\"] for r in results], ignore_index=True)\n",
    "# alm_returns_df = pd.concat([r[\"alm_df\"] for r in results if r[\"alm_df\"] is not None], ignore_index=True)\n",
    "\n",
    "# if not alm_returns_df.empty:\n",
    "#     alm_returns_df = alm_returns_df.pivot(index=\"date\", columns=\"lambda\", values=\"r_hat\").sort_index()\n",
    "\n",
    "# print(\"\\n=== Results Summary ===\")\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9970ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset = X.sample(n=60, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17905eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your grid\n",
    "param_grid = {\n",
    "    'window_sizes': [30,80,160,300,500],\n",
    "    'n_lags': [3,7,12],\n",
    "    'lambdas': [0.001,0.0001]\n",
    "}\n",
    "\n",
    "# Run grid search \n",
    "results_df3 = grid_search(X_subset, y, param_grid, verbose=True)\n",
    "\n",
    "# Save\n",
    "results_df3.to_csv('grid_search_results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fix = pd.read_csv(\"grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b52109",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([results_df1, result_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting ---\n",
    "if pd.api.types.is_datetime64_any_dtype(active_predictors_df[\"date\"]):\n",
    "    active_predictors_df[\"month\"] = active_predictors_df[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "    monthly_avg = active_predictors_df.groupby([\"lambda\", \"month\"])[\"active_predictors\"].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for lam in lambda_values:\n",
    "        subset = monthly_avg[monthly_avg[\"lambda\"] == lam]\n",
    "        plt.plot(subset[\"month\"], subset[\"active_predictors\"], marker=\"o\", label=f\"λ={lam}\")\n",
    "    \n",
    "    plt.title(\"Average Active Predictors per Month\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Average Active Predictors\")\n",
    "    plt.legend(title=\"Lambda\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ No datetime index — skipping plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cad167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Load results ----\n",
    "\n",
    "display(final_df)\n",
    "\n",
    "# Sort for consistent plotting\n",
    "final_df = final_df.sort_values(['window_size', 'lambda'])\n",
    "\n",
    "window_sizes = sorted(final_df['window_size'].unique())\n",
    "lambdas = sorted(final_df['lambda'].unique())\n",
    "\n",
    "# ============================================================\n",
    "# Compute global y-limits for consistency\n",
    "# ============================================================\n",
    "\n",
    "# In-sample R² min/max across both stages\n",
    "r2_insample_min = min(\n",
    "    final_df['r2_insample_stage1'].min(),\n",
    "    final_df['r2_insample_stage2'].min()\n",
    ")\n",
    "r2_insample_max = max(\n",
    "    final_df['r2_insample_stage1'].max(),\n",
    "    final_df['r2_insample_stage2'].max()\n",
    ")\n",
    "\n",
    "# OOS R² min/max across both stages\n",
    "r2_oos_min = min(\n",
    "    final_df['r2_oos_stage1'].min(),\n",
    "    final_df['r2_oos_stage2'].min()\n",
    ")\n",
    "r2_oos_max = max(\n",
    "    final_df['r2_oos_stage1'].max(),\n",
    "    final_df['r2_oos_stage2'].max()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. LINE PLOTS: OOS R² vs WINDOW SIZE (same y-scale)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lam in lambdas:\n",
    "    subset = final_df[final_df['lambda'] == lam]\n",
    "    plt.plot(subset['window_size'], subset['r2_oos_stage1'], marker='o', label=f\"λ={lam}\")\n",
    "plt.title(\"Stage 1 OOS R² vs Window Size\")\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.ylim(r2_oos_min, r2_oos_max)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lam in lambdas:\n",
    "    subset = final_df[final_df['lambda'] == lam]\n",
    "    plt.plot(subset['window_size'], subset['r2_oos_stage2'], marker='o', label=f\"λ={lam}\")\n",
    "plt.title(\"Stage 2 OOS R² vs Window Size\")\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.ylim(r2_oos_min, r2_oos_max)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. LINE PLOTS: IN-SAMPLE R² vs WINDOW SIZE (same y-scale)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lam in lambdas:\n",
    "    subset = final_df[final_df['lambda'] == lam]\n",
    "    plt.plot(subset['window_size'], subset['r2_insample_stage1'], marker='o', label=f\"λ={lam}\")\n",
    "plt.title(\"Stage 1 In-Sample R² vs Window Size\")\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.ylim(r2_insample_min, r2_insample_max)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lam in lambdas:\n",
    "    subset = final_df[final_df['lambda'] == lam]\n",
    "    plt.plot(subset['window_size'], subset['r2_insample_stage2'], marker='o', label=f\"λ={lam}\")\n",
    "plt.title(\"Stage 2 In-Sample R² vs Window Size\")\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.ylim(r2_insample_min, r2_insample_max)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba1c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
