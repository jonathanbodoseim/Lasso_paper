{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8a3115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd8a742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "546fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "project_root = cwd.parent.parent.parent\n",
    "data_path_stock = project_root / \"Empirical\" / \"data\" / \"stock_data.csv\"\n",
    "data = pd.read_csv(data_path_stock)\n",
    "data_path_bond = project_root / \"Empirical\" / \"data\" / \"DTB3.csv\"\n",
    "bond_returns = pd.read_csv(data_path_bond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f18f3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ceebd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['divd'] = data_clean['divd'].fillna(0)\n",
    "data_clean['total_div_dollars'] = data_clean['divd'] * data_clean['cshoc']\n",
    "data_clean['market_cap'] = data_clean['prccd'] * data_clean['cshoc']\n",
    "data_clean = data_clean[data_clean['prccd'].notna() & (data_clean['prccd'] > 0)]\n",
    "data_clean = data_clean[data_clean['cshoc'].notna() & (data_clean['cshoc'] > 0)]\n",
    "data_clean = data_clean[data_clean['market_cap'] > 0]\n",
    "data_clean[\"return\"] = (data_clean[\"prccd\"] - data_clean[\"prccd\"].shift(1)) / data_clean[\"prccd\"].shift(1)\n",
    "data_clean['return'] = data_clean['return'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c732997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DAILY_RETURN = 0.50   # 50% max gain (accounts for stock splits, etc.)\n",
    "MIN_DAILY_RETURN = -0.50  # -50% max loss (halving in a day)\n",
    "\n",
    "data_clean['return_is_outlier'] = (\n",
    "    (data_clean['return'] > MAX_DAILY_RETURN) | \n",
    "    (data_clean['return'] < MIN_DAILY_RETURN)\n",
    ")\n",
    "\n",
    "n_outliers = data_clean['return_is_outlier'].sum()\n",
    "data_clean = data_clean[~data_clean['return_is_outlier']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cacdd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_market_stats_corrected(group):\n",
    "    \"\"\"Calculate market statistics with CORRECTED dividend calculation\"\"\"\n",
    "    \n",
    "    valid = (group['market_cap'] > 0) & (group['market_cap'].notna())\n",
    "    group = group[valid]\n",
    "    \n",
    "    if len(group) == 0 or group['market_cap'].sum() == 0:\n",
    "        return pd.Series({\n",
    "            'vw_return': np.nan,\n",
    "            'total_dividends_paid': 0.0,\n",
    "            'avg_price': np.nan,\n",
    "            'total_market_cap': np.nan,\n",
    "            'n_stocks': 0\n",
    "        })\n",
    "    \n",
    "    total_mcap = group['market_cap'].sum()\n",
    "    \n",
    "    # Value-weighted return\n",
    "    vw_return = np.sum(group['return'] * group['market_cap']) / total_mcap\n",
    "    \n",
    "    # CORRECTED: Sum total dollar dividends (already multiplied by shares)\n",
    "    total_div_paid = group['total_div_dollars'].sum()\n",
    "    \n",
    "    # Value-weighted average price\n",
    "    avg_price = np.sum(group['prccd'] * group['market_cap']) / total_mcap\n",
    "    \n",
    "    return pd.Series({\n",
    "        'vw_return': vw_return,\n",
    "        'total_dividends_paid': total_div_paid,\n",
    "        'avg_price': avg_price,\n",
    "        'total_market_cap': total_mcap,\n",
    "        'n_stocks': len(group)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4eb71a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_market = data_clean.groupby('datadate').apply(\n",
    "    calculate_daily_market_stats_corrected\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f38e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_market = daily_market[daily_market['n_stocks'] >= 10].copy()\n",
    "daily_market = daily_market.dropna(subset=['vw_return', 'avg_price', 'total_market_cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5ff9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_market['datadate'] = pd.to_datetime(daily_market['datadate'], errors='coerce', dayfirst=False)\n",
    "bond_returns['observation_date'] = pd.to_datetime(bond_returns['observation_date'], errors='coerce', dayfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc652e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_market = pd.merge(\n",
    "    daily_market, \n",
    "    bond_returns, \n",
    "    left_on='datadate', \n",
    "    right_on='observation_date', \n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c8fdbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_market['bond_return'] = (1 + daily_market['DTB3']) ** (1/252) - 1\n",
    "daily_market['bond_return'] = daily_market['bond_return'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78c30a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_dividends_paid = pd.Series(daily_market['total_dividends_paid']).rolling(\n",
    "    window=252,\n",
    "    min_periods=126\n",
    ").sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fc56faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD ratio\n",
    "total_mcap = daily_market['total_market_cap'].values\n",
    "PD = total_mcap / (annual_dividends_paid + 1e-6)\n",
    "\n",
    "# Dividend yield\n",
    "div_yield = annual_dividends_paid / total_mcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6cff52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DivGrowth = np.full(len(annual_dividends_paid), np.nan)\n",
    "\n",
    "for i in range(252, len(annual_dividends_paid)):\n",
    "    if annual_dividends_paid[i-252] > 0:\n",
    "        DivGrowth[i] = annual_dividends_paid[i] / annual_dividends_paid[i-252]\n",
    "    else:\n",
    "        DivGrowth[i] = 1.0\n",
    "\n",
    "DivGrowth = pd.Series(DivGrowth).fillna(method='ffill').fillna(method='bfill').fillna(1.0).values\n",
    "DivGrowth = np.clip(DivGrowth, 0.5, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e878991",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_returns = 1 + daily_market['vw_return'].values\n",
    "bond_returns = 1 + daily_market['bond_return'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45ed134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual stock returns\n",
    "annual_ret = (np.mean(stock_returns) ** 252 - 1) * 100\n",
    "annual_vol = np.std(stock_returns) * np.sqrt(252) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c21dd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove initial period with NaNs\n",
    "valid_mask = (~np.isnan(PD)) & (~np.isnan(DivGrowth))\n",
    "first_valid = np.argmax(valid_mask)\n",
    "\n",
    "if first_valid > 0:\n",
    "    print(f\"Removing first {first_valid} observations with missing data\")\n",
    "    stock_returns = stock_returns[first_valid:]\n",
    "    bond_returns = bond_returns[first_valid:]\n",
    "    PD = PD[first_valid:]\n",
    "    DivGrowth = DivGrowth[first_valid:]\n",
    "    daily_market = daily_market.iloc[first_valid:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab18a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plots...\n",
      "  Plot 1...\n",
      "  Plot 2...\n",
      "  Plot 3...\n",
      "  Plot 4...\n",
      "  Plot 5...\n",
      "  Plot 6...\n",
      "Saving plot...\n",
      "✅ Plot saved to 'corrected_data_diagnostics.png'\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PLOTTING CODE\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the aligned versions for plotting\n",
    "dates_plot = daily_market['datadate'].values\n",
    "stock_returns_plot = stock_returns\n",
    "PD_plot = PD\n",
    "DivGrowth_plot = DivGrowth\n",
    "\n",
    "# Recalculate annual_dividends_paid for the cleaned data\n",
    "annual_dividends_paid_plot = pd.Series(daily_market['total_dividends_paid']).rolling(\n",
    "    window=252,\n",
    "    min_periods=126\n",
    ").sum().values\n",
    "\n",
    "# Recalculate other needed variables\n",
    "total_mcap_plot = daily_market['total_market_cap'].values\n",
    "div_yield_plot = annual_dividends_paid_plot / total_mcap_plot\n",
    "print(\"Creating plots...\")\n",
    "\n",
    "# Convert dates to proper format \n",
    "if isinstance(dates_plot[0], str):\n",
    "    dates_plot = pd.to_datetime(dates_plot)\n",
    "elif not isinstance(dates_plot, pd.DatetimeIndex):\n",
    "    dates_plot = pd.DatetimeIndex(dates_plot)\n",
    "\n",
    "# Create plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Daily dividends paid\n",
    "print(\"  Plot 1...\")\n",
    "axes[0, 0].plot(dates_plot, daily_market['total_dividends_paid'].values, \n",
    "                linewidth=0.5, alpha=0.7)\n",
    "axes[0, 0].set_title('Daily Total Dividends Paid ($)')\n",
    "axes[0, 0].set_ylabel('Dividends ($ millions)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.0f}M'))\n",
    "\n",
    "# Plot 2: Rolling annual dividends\n",
    "print(\"  Plot 2...\")\n",
    "axes[0, 1].plot(dates_plot, annual_dividends_paid_plot / 1e9)\n",
    "axes[0, 1].set_title('Trailing 252-Day Total Dividends')\n",
    "axes[0, 1].set_ylabel('Annual Dividends ($ Billions)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: PD ratio over time\n",
    "print(\"  Plot 3...\")\n",
    "axes[1, 0].plot(dates_plot, PD_plot, linewidth=1)\n",
    "axes[1, 0].set_title('Price-to-Dividend Ratio')\n",
    "axes[1, 0].set_ylabel('PD Ratio')\n",
    "mean_pd = np.nanmean(PD_plot)\n",
    "axes[1, 0].axhline(y=mean_pd, color='r', linestyle='--', alpha=0.5, \n",
    "                   label=f'Mean: {mean_pd:.1f}')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Dividend yield over time\n",
    "print(\"  Plot 4...\")\n",
    "axes[1, 1].plot(dates_plot, div_yield_plot * 100, linewidth=1)\n",
    "axes[1, 1].set_title('Dividend Yield (%)')\n",
    "axes[1, 1].set_ylabel('Yield (%)')\n",
    "mean_dy = np.nanmean(div_yield_plot) * 100\n",
    "axes[1, 1].axhline(y=mean_dy, color='r', \n",
    "                   linestyle='--', alpha=0.5, \n",
    "                   label=f'Mean: {mean_dy:.2f}%')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Dividend growth over time\n",
    "print(\"  Plot 5...\")\n",
    "axes[2, 0].plot(dates_plot, DivGrowth_plot, linewidth=1)\n",
    "axes[2, 0].axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='No growth')\n",
    "mean_dg = np.nanmean(DivGrowth_plot)\n",
    "axes[2, 0].axhline(y=mean_dg, color='g', linestyle='--', alpha=0.5,\n",
    "                   label=f'Mean: {mean_dg:.3f}')\n",
    "axes[2, 0].set_title('Dividend Growth (YoY)')\n",
    "axes[2, 0].set_ylabel('Growth Rate')\n",
    "axes[2, 0].legend()\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Stock returns over time\n",
    "print(\"  Plot 6...\")\n",
    "axes[2, 1].plot(dates_plot, stock_returns_plot, linewidth=0.5, alpha=0.7)\n",
    "axes[2, 1].axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='Zero return')\n",
    "axes[2, 1].set_title('Stock Returns (Gross)')\n",
    "axes[2, 1].set_ylabel('Gross Return')\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "axes[2, 1].set_ylim([0.95, 1.05])\n",
    "\n",
    "# Format x-axes for all subplots\n",
    "for ax in axes.flat:\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(2))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"Saving plot...\")\n",
    "plt.savefig('corrected_data_diagnostics.png', dpi=150, bbox_inches='tight')  # Lower DPI for speed\n",
    "print(\"✅ Plot saved to 'corrected_data_diagnostics.png'\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e947eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "Sample Information:\n",
      "  Start date: 2010-07-02 00:00:00\n",
      "  End date: 2025-10-09 00:00:00\n",
      "  Number of days: 3,842\n",
      "  Number of years: 15.2\n",
      "\n",
      "Stock Returns:\n",
      "  Mean (daily): 1.000803 (0.0803%)\n",
      "  Std (daily): 0.010524\n",
      "  Mean (annual): 22.41%\n",
      "  Vol (annual): 16.71%\n",
      "\n",
      "PD Ratio:\n",
      "  Mean: 56.13\n",
      "  Median: 52.31\n",
      "  Std: 9.31\n",
      "  Range: [36.74, 92.25]\n",
      "\n",
      "Dividend Yield:\n",
      "  Mean: 1.82%\n",
      "  Median: 1.92%\n",
      "\n",
      "Dividend Growth:\n",
      "  Mean: 1.0933 (+9.33%)\n",
      "  Median: 1.0765\n",
      "  Std: 0.1120\n",
      "\n",
      "Market Capitalization:\n",
      "  Mean: $23172.86 billion\n",
      "  Median: $21265.68 billion\n",
      "\n",
      "Annual Dividends:\n",
      "  Mean: $410.28 billion\n",
      "  Median: $420.10 billion\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nSample Information:\")\n",
    "print(f\"  Start date: {dates_plot[0]}\")\n",
    "print(f\"  End date: {dates_plot[-1]}\")\n",
    "print(f\"  Number of days: {len(dates_plot):,}\")\n",
    "print(f\"  Number of years: {len(dates_plot)/252:.1f}\")\n",
    "\n",
    "print(f\"\\nStock Returns:\")\n",
    "print(f\"  Mean (daily): {np.mean(stock_returns_plot):.6f} ({(np.mean(stock_returns_plot)-1)*100:.4f}%)\")\n",
    "print(f\"  Std (daily): {np.std(stock_returns_plot):.6f}\")\n",
    "print(f\"  Mean (annual): {(np.mean(stock_returns_plot)**252 - 1)*100:.2f}%\")\n",
    "print(f\"  Vol (annual): {np.std(stock_returns_plot)*np.sqrt(252)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nPD Ratio:\")\n",
    "print(f\"  Mean: {np.nanmean(PD_plot):.2f}\")\n",
    "print(f\"  Median: {np.nanmedian(PD_plot):.2f}\")\n",
    "print(f\"  Std: {np.nanstd(PD_plot):.2f}\")\n",
    "print(f\"  Range: [{np.nanmin(PD_plot):.2f}, {np.nanmax(PD_plot):.2f}]\")\n",
    "\n",
    "print(f\"\\nDividend Yield:\")\n",
    "print(f\"  Mean: {np.nanmean(div_yield_plot)*100:.2f}%\")\n",
    "print(f\"  Median: {np.nanmedian(div_yield_plot)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nDividend Growth:\")\n",
    "print(f\"  Mean: {np.nanmean(DivGrowth_plot):.4f} ({(np.nanmean(DivGrowth_plot)-1)*100:+.2f}%)\")\n",
    "print(f\"  Median: {np.nanmedian(DivGrowth_plot):.4f}\")\n",
    "print(f\"  Std: {np.nanstd(DivGrowth_plot):.4f}\")\n",
    "\n",
    "print(f\"\\nMarket Capitalization:\")\n",
    "print(f\"  Mean: ${np.nanmean(total_mcap_plot)/1e9:.2f} billion\")\n",
    "print(f\"  Median: ${np.nanmedian(total_mcap_plot)/1e9:.2f} billion\")\n",
    "\n",
    "print(f\"\\nAnnual Dividends:\")\n",
    "print(f\"  Mean: ${np.nanmean(annual_dividends_paid_plot)/1e9:.2f} billion\")\n",
    "print(f\"  Median: ${np.nanmedian(annual_dividends_paid_plot)/1e9:.2f} billion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9f373",
   "metadata": {},
   "source": [
    "Now calculate the moments matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2a3fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPUTING MOMENTS AND WEIGHTING MATRIX (DAILY DATA)\n",
      "============================================================\n",
      "\n",
      "Parameters:\n",
      "  Lag (years): 1\n",
      "  Lag (days): 1\n",
      "  Method: Newey-West\n",
      "\n",
      "============================================================\n",
      "USING PREPARED DATA\n",
      "============================================================\n",
      "\n",
      "Data loaded:\n",
      "  Stock returns (rs): 3,842 observations\n",
      "  Bond returns (rb): 3,842 observations\n",
      "  PD ratio: 3,842 observations\n",
      "  Dividend growth: 3,842 observations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE MOMENTS AND WEIGHTING MATRIX FOR DAILY DATA\n",
    "# Adapted from Adam, Marcet, Nicolini (2016) computeWeightMatrix.m\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPUTING MOMENTS AND WEIGHTING MATRIX (DAILY DATA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# For daily data, adjust the lag parameter\n",
    "# Original uses 5 years = 20 quarters\n",
    "# For daily: 5 years = 5 * 252 = 1260 trading days\n",
    "lag_years = 1\n",
    "lag_days = lag_years   # 1260 trading days\n",
    "\n",
    "method = 1  # 1 for Newey-West, 2 for den Haan-Levin\n",
    "do_fullsample = 0  # 0 to use same sample for all statistics\n",
    "\n",
    "print(f\"\\nParameters:\")\n",
    "print(f\"  Lag (years): {lag_years}\")\n",
    "print(f\"  Lag (days): {lag_days}\")\n",
    "print(f\"  Method: {'Newey-West' if method == 1 else 'den Haan-Levin'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Use the cleaned data from previous steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"USING PREPARED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# These should already exist from your data preparation:\n",
    "# - stock_returns (gross returns)\n",
    "# - PD (price-dividend ratio)\n",
    "# - DivGrowth (dividend growth)\n",
    "\n",
    "rs = stock_returns  # Gross stock returns\n",
    "PD_array = PD       # Price-dividend ratio\n",
    "DivGrowth_array = DivGrowth  # Dividend growth\n",
    "rb = bond_returns\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Stock returns (rs): {len(rs):,} observations\")\n",
    "print(f\"  Bond returns (rb): {len(rb):,} observations\")\n",
    "print(f\"  PD ratio: {len(PD_array):,} observations\")\n",
    "print(f\"  Dividend growth: {len(DivGrowth_array):,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cfe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUILDING ADDITIONAL SERIES\n",
      "============================================================\n",
      "  ✅ PD_PDlag length: 3842\n",
      "  ✅ rs_rslag length: 3842\n",
      "  ✅ Daily excess return length: 3842\n",
      "  ✅ PD * daily excess return length: 3842\n",
      "  ✅ All series built successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BUILDING ADDITIONAL SERIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# -------------------------------\n",
    "# PD(t) * PD(t-1) (For autocorrelation of PD Ratio)\n",
    "# -------------------------------\n",
    "PD_array = np.asarray(PD_array)  # ensure numpy array\n",
    "PD_PDlag = np.full(len(PD_array), np.nan)\n",
    "PD_PDlag[1:] = PD_array[1:] * PD_array[:-1]\n",
    "\n",
    "# -------------------------------\n",
    "# rs(t) * rs(t-1) (For autocorrelation of Returns)\n",
    "# -------------------------------\n",
    "rs = np.asarray(rs)\n",
    "rs_rslag = np.full(len(rs), np.nan)\n",
    "rs_rslag[1:] = rs[1:] * rs[:-1]\n",
    "\n",
    "# -------------------------------\n",
    "# Daily excess returns\n",
    "# -------------------------------\n",
    "# Ensure rb is numpy array\n",
    "rb = np.asarray(rb)\n",
    "\n",
    "# excess return\n",
    "excret = rs - rb\n",
    "\n",
    "# Convert to pandas Series \n",
    "excret = pd.Series(excret, name=\"excess_return\")\n",
    "\n",
    "# -------------------------------\n",
    "# PD * daily excess return\n",
    "# -------------------------------\n",
    "# Align lengths: PD_array and excret\n",
    "PD_excret = PD_array * excret\n",
    "PD_excret = pd.Series(PD_excret, name=\"PD_excess_return\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87d4ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Observations: 3840\n",
      "  Matrix shape: (13, 3840)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Build h(y) matrix\n",
    "# ============================================================================\n",
    "# h(y) is the moments vecotr at the observational level\n",
    "# the result is a 13xN matrix where each row corresponds to a specific empirical moment function based on the observed data\n",
    "\n",
    "n_obs = len(rs) - 1 - lag_days\n",
    "print(f\"  Observations: {n_obs}\")\n",
    "\n",
    "# Initialize\n",
    "hy = np.zeros((13, n_obs))\n",
    "\n",
    "# Fill matrix\n",
    "hy[0, :] = rs[1:-lag_days]\n",
    "hy[1, :] = rb[1:-lag_days]\n",
    "hy[2, :] = PD_array[1:-lag_days]\n",
    "hy[3, :] = DivGrowth_array[1:-lag_days]\n",
    "hy[4, :] = hy[0, :] ** 2\n",
    "hy[5, :] = hy[2, :] ** 2\n",
    "hy[6, :] = hy[3, :] ** 2\n",
    "hy[7, :] = PD_PDlag[1:-lag_days]\n",
    "hy[8, :] = excret[1:-lag_days]\n",
    "hy[9, :] = excret[1:-lag_days] ** 2\n",
    "hy[10, :] = PD_excret[1:-lag_days]\n",
    "hy[11, :] = hy[1, :] ** 2\n",
    "hy[12, :] = rs_rslag[1:-lag_days]\n",
    "\n",
    "print(f\"  Matrix shape: {hy.shape}\")\n",
    "\n",
    "N = hy.shape[1]\n",
    "M = np.mean(hy, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPUTING STATISTICS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EMPIRICAL MOMENTS (DAILY DATA)\n",
      "============================================================\n",
      " 1. E(r^s)         :   1.000805\n",
      " 2. E(r^b)         :   1.002490\n",
      " 3. E(PD)          :  56.115434\n",
      " 4. E(D/d)         :   1.093333\n",
      " 5. sigma_r^s      :   0.010527\n",
      " 6. sigma_PD       :   9.291257\n",
      " 7. sigma_D/d      :   0.111995\n",
      " 8. autcorr_PD     :   1.000157\n",
      " 9. betaPD         :  -0.000063\n",
      "10. R^2            :   0.002863\n",
      "11. sigma_r^b      :   0.002670\n",
      "12. autcorr_r^s    :  -0.144499\n",
      "\n",
      "Annualized:\n",
      "  Return: 22.48%\n",
      "  Volatility: 16.71%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Compute statistics S(M)\n",
    "# ============================================================================\n",
    "# this cell maps the observed moments into statistics (some functions S are nonlinear, e.g.: R2, autocorellation)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTING STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "S = np.zeros(12)\n",
    "\n",
    "S[0] = M[0]\n",
    "S[1] = M[1]\n",
    "S[2] = M[2]\n",
    "S[3] = M[3]\n",
    "S[4] = np.sqrt(max(M[4] - M[0]**2, 1e-10))\n",
    "S[5] = np.sqrt(max(M[5] - M[2]**2, 1e-10))\n",
    "S[6] = np.sqrt(max(M[6] - M[3]**2, 1e-10))\n",
    "S[7] = (M[7] - M[2]**2) / (S[5]**2 + 1e-10)\n",
    "S[8] = (M[10] - M[2]*M[8]) / (S[5]**2 + 1e-10)\n",
    "S[9] = S[8]**2 * S[5]**2 / max(M[9] - M[8]**2, 1e-10)\n",
    "S[10] = np.sqrt(max(M[11] - M[1]**2, 1e-10))\n",
    "S[11] = (M[12] - M[0]**2) / (S[4]**2 + 1e-10)\n",
    "\n",
    "stat_labels = [\n",
    "    'E(r^s)', 'E(r^b)', 'E(PD)', 'E(D/d)',\n",
    "    'sigma_r^s', 'sigma_PD', 'sigma_D/d', 'autcorr_PD',\n",
    "    'betaPD', 'R^2', 'sigma_r^b', 'autcorr_r^s'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EMPIRICAL MOMENTS (DAILY DATA)\")\n",
    "print(\"=\"*60)\n",
    "for i, (label, value) in enumerate(zip(stat_labels, S)):\n",
    "    print(f\"{i+1:2d}. {label:<15}: {value:10.6f}\")\n",
    "\n",
    "# Annualized\n",
    "annual_ret = (S[0] ** 252 - 1) * 100\n",
    "annual_vol = S[4] * np.sqrt(252) * 100\n",
    "\n",
    "print(f\"\\nAnnualized:\")\n",
    "print(f\"  Return: {annual_ret:.2f}%\")\n",
    "print(f\"  Volatility: {annual_vol:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6747a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPUTING JACOBIAN (VECTORIZED & SAFE)\n",
      "============================================================\n",
      "  Shape: (12, 13), Non-zero elements: 26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTING JACOBIAN (VECTORIZED & SAFE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Small epsilon to avoid divide-by-zero\n",
    "eps = 1e-10\n",
    "\n",
    "# Ensure S elements that appear in denominators are safe\n",
    "S_safe = np.copy(S)\n",
    "S_safe[[4,5,6,10]] = np.maximum(S_safe[[4,5,6,10]], eps)\n",
    "\n",
    "# Initialize Jacobian\n",
    "dS = np.zeros((len(S), len(M)))\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Means are direct derivatives\n",
    "# -------------------------------\n",
    "for i in range(4):\n",
    "    dS[i, i] = 1.0\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Standard deviations: sigma = sqrt(M_var - M_mean^2)\n",
    "# -------------------------------\n",
    "dS[4, 4] = 1.0 / (2*S_safe[4])\n",
    "dS[4, 0] = -M[0] / S_safe[4]\n",
    "\n",
    "dS[5, 5] = 1.0 / (2*S_safe[5])\n",
    "dS[5, 2] = -M[2] / S_safe[5]\n",
    "\n",
    "dS[6, 6] = 1.0 / (2*S_safe[6])\n",
    "dS[6, 3] = -M[3] / S_safe[6]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Autocorrelation: rho = (M_lag - M_mean^2) / sigma^2\n",
    "# -------------------------------\n",
    "dS[7, 7] = 1.0 / S_safe[5]**2\n",
    "dS[7, 2] = -2*M[2] / S_safe[5]**2\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Beta (S[8]) and R² (S[9])\n",
    "# -------------------------------\n",
    "# Beta: beta = (M[10] - M[2]*M[8]) / sigma_PD^2\n",
    "dS[8, 2] = (-M[8]*S_safe[5]**2 - 2*S_safe[5]*(-M[2]/2))*S_safe[5]**-2\n",
    "dS[8, 5] = -2*(S[8]/S_safe[5])*dS[5,5]  # chain rule\n",
    "dS[8, 8] = -M[2]/S_safe[5]**2\n",
    "dS[8,10] = 1.0 / S_safe[5]**2\n",
    "\n",
    "# R²: R² = beta^2 * sigma_PD^2 / (var(Y))\n",
    "denom_r2 = M[9] - M[8]**2\n",
    "denom_r2 = max(denom_r2, eps)\n",
    "dS[9,2]  = (2*S[8]*dS[8,2]*S_safe[5]**2 + 2*S[8]**2*S_safe[5]*dS[5,2])/denom_r2\n",
    "dS[9,5]  = (2*S[8]*dS[8,5]*S_safe[5]**2 + 2*S[8]**2*S_safe[5]*dS[5,5])/denom_r2\n",
    "dS[9,8]  = ((2*S[8]*dS[8,8]*S_safe[5]**2 + 2*S[8]**2*S_safe[5]*0)*denom_r2 - (-2*M[8]*S[8]**2*S_safe[5]**2))/denom_r2**2\n",
    "dS[9,9]  = -S[8]**2*S_safe[5]**2 / denom_r2**2\n",
    "dS[9,10] = 2*S[8]/denom_r2\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Remaining standard deviations and autocorrelation\n",
    "# -------------------------------\n",
    "dS[10,11] = 1.0 / (2*S_safe[10])\n",
    "dS[10,1]  = -M[1]/S_safe[10]\n",
    "\n",
    "dS[11,12] = 1.0 / S_safe[4]**2\n",
    "dS[11,0]  = 2*M[0]*(M[12]-M[4])/S_safe[4]**4\n",
    "dS[11,4]  = -2*(S[11]/S_safe[4])*dS[4,4]\n",
    "\n",
    "print(f\"  Shape: {dS.shape}, Non-zero elements: {np.sum(dS != 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPUTING NEWEY-WEST\n",
      "============================================================\n",
      "  K = 960\n",
      "  ✅ Sw computed\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: Newey-West\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTING NEWEY-WEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "Mn = np.tile(M.reshape(-1, 1), (1, N))\n",
    "hy_Mn = hy - Mn\n",
    "C0 = (1.0 / N) * (hy_Mn @ hy_Mn.T)\n",
    "\n",
    "K = int(np.floor(N / 4))\n",
    "print(f\"  K = {K}\")\n",
    "\n",
    "Cj = np.zeros((len(M), len(M), K))\n",
    "for j in range(K):\n",
    "    wjK = (1 - (j + 1) / (K + 1)) * (1.0 / (N - j - 1))\n",
    "    Cj[:, :, j] = wjK * (hy_Mn[:, j+1:] @ hy_Mn[:, :-(j+1)].T)\n",
    "\n",
    "Sw = C0.copy()\n",
    "for j in range(K):\n",
    "    Sw = Sw + (Cj[:, :, j] + Cj[:, :, j].T)\n",
    "\n",
    "print(f\"  ✅ Sw computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WEIGHT MATRIX\n",
      "============================================================\n",
      "  ⚠️  Using pseudo-inverse\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: Weight matrix\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WEIGHT MATRIX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dS_Sw_dS = dS @ Sw @ dS.T\n",
    "\n",
    "eigenvalues = linalg.eigvals(dS_Sw_dS)\n",
    "if np.min(eigenvalues.real) > 0:\n",
    "    print(\"  ✅ Positive definite\")\n",
    "    W = linalg.inv(dS_Sw_dS)\n",
    "else:\n",
    "    print(\"  ⚠️  Using pseudo-inverse\")\n",
    "    W = linalg.pinv(dS_Sw_dS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ COMPLETE! Results saved.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE\n",
    "# ============================================================================\n",
    "\n",
    "np.savez('daily_moment_calculations.npz',\n",
    "         S=S, dS_Sw_dS=dS_Sw_dS, W=W, M=M, dS=dS, Sw=Sw,\n",
    "         N=N, lag_days=lag_days,\n",
    "         stat_labels=np.array(stat_labels, dtype=object))\n",
    "\n",
    "pd.DataFrame({'Statistic': stat_labels, 'Value': S}).to_csv('daily_empirical_moments.csv', index=False)\n",
    "\n",
    "print(\"\\n✅ COMPLETE! Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narratives_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
